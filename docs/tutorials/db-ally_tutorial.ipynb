{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UtFgH93FkX7"
   },
   "source": [
    "#db-ally tutorial\n",
    "\n",
    "In this tutorial, we are going to build a robust, explainable, and prompt-efficient chat agent, which will answer questions regarding the HR-recruitment database. We will use [**db-ally**](https://db-ally.deepsense.ai/) - `Efficient, consistent and secure library for querying structured data with natural language` and [SQLite](https://www.sqlite.org/) database served with the help of [sqlalchemy](https://www.sqlalchemy.org/).\n",
    "\n",
    "Throughout the lesson, we will be working with the following HR database.\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1A5yPt-pIyXGV94c6cMIkMf8AhiP6Nnq6\" alt=\"Database schema\" width=\"700\" height=\"auto\">\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install [**db-ally**](https://db-ally.deepsense.ai/) with the openai extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zZmdC00Y31E"
   },
   "outputs": [],
   "source": [
    "!pip install dbally[litellm] a-world-of-countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgOk_RYCXcP9"
   },
   "source": [
    "Download the [`hr database file`](https://drive.google.com/file/d/1A5yPt-pIyXGV94c6cMIkMf8AhiP6Nnq6/view?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fptUfxhyEiC6"
   },
   "outputs": [],
   "source": [
    "!wget -O recruitment.db 'https://drive.google.com/uc?export=download&id=1zo3j8x7qH8opTKyQ9qFgRpS3yqU6uTRs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr_6BnaoMYu2"
   },
   "source": [
    "Next, we need to:\n",
    "1. Create the database (`ENGINE`). Thanks, [SQLite In-memory database](https://www.sqlite.org/inmemorydb.html) we can load the file directly.\n",
    "2. Define ORM Model (`RECRUITMENT_MODEL`) with [sqlalchemy automap](https://docs.sqlalchemy.org/en/20/orm/extensions/automap.html)\n",
    "3. Check that everything went well with [selecting](https://docs.sqlalchemy.org/en/20/tutorial/data_select.html) and printing 5 rows of every table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1g6teH42MyQV"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import select\n",
    "\n",
    "ENGINE = create_engine(\"sqlite:///recruitment.db\")\n",
    "\n",
    "RECRUITMENT_MODEL = automap_base()\n",
    "RECRUITMENT_MODEL.prepare(autoload_with=ENGINE, reflect=True)\n",
    "\n",
    "# Verify that all entires were created\n",
    "stmts = [\n",
    "    select(RECRUITMENT_MODEL.classes.candidate),\n",
    "    select(RECRUITMENT_MODEL.classes.application),\n",
    "    select(RECRUITMENT_MODEL.classes.offer),\n",
    "]\n",
    "\n",
    "with ENGINE.connect() as conn:\n",
    "    for stmt in stmts:\n",
    "        for row in conn.execute(stmt.limit(5)):\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d99L-hcvTTTd"
   },
   "source": [
    "## Create the first view\n",
    "\n",
    "Our database is ready! The next task is to create the first version of our agent and have a conversation ðŸ—¨\n",
    "\n",
    "Let's:\n",
    "1. Create a [View](https://db-ally.deepsense.ai/concepts/views/) in which we define functions accessible to the [Intermediate Query Language](https://db-ally.deepsense.ai/concepts/iql/) (IQL) engine.\n",
    "2. Write `get_select` function that provides a foundation of the [`SELECT`](https://www.w3schools.com/sql/sql_select.asp) statement generated by the [IQL engine](https://db-ally.deepsense.ai/concepts/iql/)\n",
    "3. Create our first filter `at_least_experience` using [ORM querying possibilities](https://docs.sqlalchemy.org/en/20/orm/queryguide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zcc5JUOVSoas"
   },
   "outputs": [],
   "source": [
    "from dbally import SqlAlchemyBaseView, decorators\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "class CandidateView(SqlAlchemyBaseView):\n",
    "    \"\"\"\n",
    "    View meant for answering questions just about the candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_select(self) -> sqlalchemy.Select:\n",
    "        return select(RECRUITMENT_MODEL.classes.candidate)\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def at_least_experience(self, years: int) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMOqwCerubIX"
   },
   "source": [
    "Now our agent can use this view to query the database. To accomplish this we need to create `ask_dbally` function:\n",
    "1. Set up dbally to [use particular LLM](https://db-ally.deepsense.ai/how-to/use_custom_llm/) and provide the API_KEY\n",
    "2. Set [CLIEventHandler](https://db-ally.deepsense.ai/how-to/create_custom_event_handler/) - This will print all intermediate conversation steps.\n",
    "3. Create a [Collection](https://db-ally.deepsense.ai/concepts/collections/) that is a queryable container of different [Views](https://db-ally.deepsense.ai/concepts/views/).\n",
    "4. Mark the fynction as `async`. It is necessary since Collection is [asynchronous](https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)).\n",
    "5. Execute `run_dbally`, providing it the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ST-QdCciuUNE"
   },
   "outputs": [],
   "source": [
    "from dbally.audit.event_handlers.cli_event_handler import CLIEventHandler\n",
    "from dbally.llms.litellm import LiteLLM\n",
    "import dbally\n",
    "\n",
    "API_KEY = \"API-KEY-GOES-HERE\"\n",
    "\n",
    "\n",
    "async def ask_dbally(question: str):\n",
    "    llm = LiteLLM(api_key=API_KEY)\n",
    "    recruitment_db = dbally.create_collection(\"recruitment\", llm, event_handlers=[CLIEventHandler()])\n",
    "    recruitment_db.add(CandidateView, lambda: CandidateView(ENGINE))\n",
    "\n",
    "    await recruitment_db.ask(question)\n",
    "\n",
    "\n",
    "await ask_dbally(\"Which candidates have more than 5 years of experience?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGHyVZTX2myp"
   },
   "source": [
    "You should see a conversation between you and the agent. Notice that:\n",
    "1. LLM is given all filters we've created and instructions on how to use them (see [prompt description](docs) for more details)\n",
    "```\n",
    "at_least_experience(years: int)\n",
    "```\n",
    "2. LLM produced an [IQL](docs) query.\n",
    "```\n",
    "RESPONSE: at_least_experience(5)\n",
    "```\n",
    "\n",
    "3. Based on the output of 2. the [IQL engine](docs) generated a proper SQL that is later executed.\n",
    "\n",
    "```sql\n",
    "SELECT candidate.id, candidate.name, candidate.country, candidate.years_of_experience, candidate.position,         \n",
    "candidate.university, candidate.skills, candidate.tags                                                             \n",
    "FROM candidate                                                                                                     \n",
    "WHERE candidate.years_of_experience >= 5   \n",
    "```\n",
    "\n",
    "\n",
    "### Ask an unsupported question\n",
    "\n",
    "Pay attention to the part of the prompt instructing LLM to return `UnexpectedQueryError` if there are no such filters to answer the query. Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyWHvCcd40KT"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Who studied at Stanford?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRI2y1zz7Fkx"
   },
   "source": [
    "**Remark**: We should see `UnexpectedQueryError`. However, even though we state very strongly in the prompt that LLM should not fabricate any filter, it is non-deterministic, so hallucinations are still possible.\n",
    "\n",
    "## Add more filters\n",
    "\n",
    "Let's add more capabilities to our agent by defining the following filters:\n",
    "\n",
    "1. `has_seniority` - Encodes domain knowledge specific to a given company.\n",
    "2. `is_from_continent` - Uses an external API to inject knowledge about countries within continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOOJfg-T8aqP"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import awoc\n",
    "\n",
    "\n",
    "class CandidateView(SqlAlchemyBaseView):\n",
    "    \"\"\"\n",
    "    View meant for answering questions just about the candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_select(self) -> sqlalchemy.Select:\n",
    "        return select(RECRUITMENT_MODEL.classes.candidate)\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def at_least_experience(self, years: int) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= years\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def has_seniority(self, seniority: Literal[\"junior\", \"senior\", \"mid\"]) -> sqlalchemy.ColumnElement:\n",
    "        \"\"\"Allows filtering candidates based on their seniority\"\"\"\n",
    "        if seniority == \"junior\":\n",
    "            return RECRUITMENT_MODEL.classes.candidate.years_of_experience < 2\n",
    "        if seniority == \"mid\":\n",
    "            return RECRUITMENT_MODEL.classes.candidate.years_of_experience < 5\n",
    "\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= 5\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def is_from_continent(\n",
    "        self, continent: Literal[\"Europe\", \"Asia\", \"Africa\", \"North America\", \"South America\", \"Australia\"]\n",
    "    ) -> sqlalchemy.ColumnElement:\n",
    "        my_world = awoc.AWOC()\n",
    "        wanted_countries = my_world.get_countries_list_of(continent)\n",
    "        return RECRUITMENT_MODEL.classes.candidate.country.in_(wanted_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc6TNwDh-O3U"
   },
   "source": [
    "Ask  a question about senior candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZXEQU-N-RoU"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Are there any senior candidates?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJQX0jJg-mVN"
   },
   "source": [
    "Once more, Let's take a quick look at the list of filters provided to the agent\n",
    "\n",
    "```\n",
    "at_least_experience(years: int)\n",
    "has_seniority(seniority: Literal['junior', 'senior', 'mid']) Allows filtering candidates based on their seniority\n",
    "is_from_continent(self, continent: Literal[\"Europe\", \"Asia\", \"Africa\", \"North America\", \"South America\", \"Australia\"])\n",
    "```\n",
    "\n",
    "There are three things to be noticed:\n",
    "1. Agent has access to more filters\n",
    "2. All type hints are passed to the prompt automatically\n",
    "3. Docstring of `has_seniority` function is available inside the prompt to allay any doubts.\n",
    "\n",
    "Proceed and ask about developers based in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIA5vcS7-20r"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Which developers are based in Europe?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SvSYan__nLl"
   },
   "source": [
    "Notice the generated query\n",
    "\n",
    "```sql\n",
    "SELECT candidate.id, candidate.name, candidate.country, candidate.years_of_experience, candidate.position,         \n",
    "candidate.university, candidate.skills, candidate.tags                                                             \n",
    "FROM candidate                                                                                                     \n",
    "WHERE candidate.country IN ('Albania', 'Andorra', 'Austria', 'Belarus', 'Belgium', 'Bosnia and Herzegovina',       \n",
    "'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Faroe Islands', 'Finland', 'France',     \n",
    "'Germany', 'Gibraltar', 'Greece', 'Guernsey', 'Hungary', 'Iceland', 'Ireland', 'Isle of Man', 'Italy', 'Jersey',   \n",
    "'Kosovo', 'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia', 'Malta', 'Moldova', 'Monaco',         \n",
    "'Montenegro', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Russia', 'San Marino', 'Serbia',          \n",
    "'Slovakia', 'Slovenia', 'Spain', 'Svalbard and Jan Mayen', 'Sweden', 'Switzerland', 'Ukraine', 'United Kingdom',   \n",
    "'Vatican')\n",
    "```\n",
    "\n",
    "We didn't have to inject this knowledge into the prompt - we saved many tokens. Additionally, there is no chance of hallucinations (skipping or creating new countries) since everything is hardcoded inside the API.\n",
    "\n",
    "## Combine conditions\n",
    "\n",
    "So far, all [IQL](https://db-ally.deepsense.ai/concepts/iql/) expressions have been built from one filter. Normally, we are often interested in combinations of conditions. Let's examine the possibilities that we have\n",
    "\n",
    "### Let the model do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGSWE0q2_5bT"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Are there any senior candidates that are based in either of Americas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9avHRq2mBAUz"
   },
   "source": [
    "Next, look closely at the generated IQL\n",
    "\n",
    "```sql\n",
    "RESPONSE: has_seniority(\"senior\") AND (is_from_continent(\"North America\") OR is_from_continent(\"South America\"))\n",
    "```\n",
    "\n",
    "[How does LLM now how to connect these filters?](https://db-ally.deepsense.ai/concepts/iql/)\n",
    "\n",
    "### Code it by yourself\n",
    "\n",
    "It may be tedious for the end user to write such convoluted queries manually. Imagine asking `Give me a candidate with 5 years of experience, from Europe, knowing Python, C++, and Machine Learning ... who is also a good team player`\n",
    "\n",
    "To facilitate more direct questions, we utilize [AND SqlAlchemy functionality](https://docs.sqlalchemy.org/en/20/core/sqlelement.html) to create our next filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAdApSAlBuTP"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import and_\n",
    "\n",
    "\n",
    "class CandidateView(SqlAlchemyBaseView):\n",
    "    \"\"\"\n",
    "    View meant for answering questions just about the candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_select(self) -> sqlalchemy.Select:\n",
    "        return select(RECRUITMENT_MODEL.classes.candidate)\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def at_least_experience(self, years: int) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= years\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def has_seniority(self, seniority: Literal[\"junior\", \"senior\", \"mid\"]) -> sqlalchemy.ColumnElement:\n",
    "        \"\"\"Do not use argument name in function call, just the value, remember about the quotes!\"\"\"\n",
    "        if seniority == \"junior\":\n",
    "            return RECRUITMENT_MODEL.classes.candidate.years_of_experience < 2\n",
    "        if seniority == \"mid\":\n",
    "            return RECRUITMENT_MODEL.classes.candidate.years_of_experience < 5\n",
    "\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= 5\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def is_from_continent(\n",
    "        self, continent: Literal[\"Europe\", \"Asia\", \"Africa\", \"North America\", \"South America\", \"Australia\"]\n",
    "    ) -> sqlalchemy.ColumnElement:\n",
    "        my_world = awoc.AWOC()\n",
    "        wanted_countries = my_world.get_countries_list_of(continent)\n",
    "        return RECRUITMENT_MODEL.classes.candidate.country.in_(wanted_countries)\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def data_scientist_position(self) -> sqlalchemy.ColumnElement:\n",
    "        \"\"\"Defines a perfect candidate for data scientist position.\"\"\"\n",
    "        return and_(\n",
    "            RECRUITMENT_MODEL.classes.candidate.position.in_([\"Data Scientist\", \"Machine Learning Engineer\"]),\n",
    "            RECRUITMENT_MODEL.classes.candidate.years_of_experience >= 3,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nShWfsomBPME"
   },
   "source": [
    "Then, we ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Car5lITECA1V"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Return all candidate suitable for data scientist position?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DTqq1R8CB8G"
   },
   "source": [
    "## [Natural Language Response](https://db-ally.deepsense.ai/concepts/nl_responder/)\n",
    "\n",
    "So far we could only see the executed SQL Query. For programmers, it may be enough but for the end user, the response in the natural language is much better.\n",
    "\n",
    "Simply modify `ask_dbally` function by adding a `return_natural_reponse=True` flag to the call to the `ask` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ckqM-kNDwuI"
   },
   "outputs": [],
   "source": [
    "async def ask_dbally(question: str):\n",
    "    llm = LiteLLM(api_key=API_KEY)\n",
    "    recruitment_db = dbally.create_collection(\"recruitment\", llm, event_handlers=[CLIEventHandler()])\n",
    "    recruitment_db.add(CandidateView, lambda: CandidateView(ENGINE))\n",
    "\n",
    "    await recruitment_db.ask(question, return_natural_response=True)\n",
    "\n",
    "\n",
    "await ask_dbally(\"Return all candidate suitable for data scientist position?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLd8leelEDth"
   },
   "source": [
    "Now, besides the typical conversation seen so far, you should see the prompt, retrieved table, and natural response from the agent.\n",
    "\n",
    "```\n",
    "system\n",
    "You are a helpful assistant that helps answer the user's questions based on the table provided. You MUST use the table to answer the question. You are very intelligent and obedient.\n",
    "The table ALWAYS contains full answer to a question.\n",
    "Answer the question in a way that is easy to understand and informative.\n",
    "DON'T MENTION using a table in your answer.\n",
    "\n",
    "user\n",
    "The table below represents the answer to a question: Return all candidate suitable for data scientist position?.\n",
    "+------+----------------+-------------+-----------------------+---------------------------+----------------------------------------------------+---------------------------------------+--------------------------------------+\n",
    "|   id | name           | country     |   years_of_experience | position                  | university                                         | skills                                | tags                                 |\n",
    "|------+----------------+-------------+-----------------------+---------------------------+----------------------------------------------------+---------------------------------------+--------------------------------------|\n",
    "|    1 | Emily Chen     | Canada      |                     3 | Data Scientist            | University of Toronto                              | R;Python;Machine Learning             | Data Analysis Research               |\n",
    "|   10 | Daniel Kim     | South Korea |                     6 | Machine Learning Engineer | Korea Advanced Institute of Science and Technology | Python;Machine Learning;Deep Learning | Artificial Intelligence;Data Science |\n",
    "|   30 | Anushka Sharma | India       |                     5 | Data Scientist            | Indian Institute of Technology Bombay              | Python;R;Machine Learning             | Data Analysis;Predictive Modeling    |\n",
    "+------+----------------+-------------+-----------------------+---------------------------+----------------------------------------------------+---------------------------------------+--------------------------------------+\n",
    "Answer the question: Return all candidate suitable for data scientist position?.\n",
    "\n",
    "RESPONSE: Emily Chen from Canada and Anushka Sharma from India are suitable candidates for the Data Scientist position. Emily Chen has 3 years of experience and holds a degree from the University of\n",
    "Toronto. She is proficient in R, Python, and Machine Learning, with skills in Data Analysis and Research. On the other hand, Anushka Sharma has 5 years of experience and is an alumnus of the Indian\n",
    "Institute of Technology Bombay. She is skilled in Python, R, and Machine Learning, with expertise in Data Analysis and Predictive Modeling.\n",
    "```\n",
    "## Joined view\n",
    "\n",
    "So far we've been querying only the Candidate table. It is quite limiting, so let's overcome it by creating a view that [joins](https://docs.sqlalchemy.org/en/14/orm/queryguide.html#joins) all three tables:\n",
    "\n",
    "1. We need to redefine `get_select` function to return joined view:\n",
    "  1. Provide only a candidate column to the select statement.\n",
    "  2. join all columns on the [foreign keys](https://www.w3schools.com/sql/sql_foreignkey.asp)\n",
    "2. We write filters utilizing this joined view. Notice that every filter uses a different table.\n",
    "\n",
    "**Remark:** the only thing that's changed in the `ask_dbally` is an exchange of CandidateView to RecruitmentView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfC0C5k4MgUd"
   },
   "outputs": [],
   "source": [
    "class RecruitmentView(SqlAlchemyBaseView):\n",
    "    \"\"\"\n",
    "    Joined view of the entire database, meant for answering questions mixing candidate, job_offer and application tables.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_select(self) -> sqlalchemy.Select:\n",
    "        return (\n",
    "            select(RECRUITMENT_MODEL.classes.candidate)\n",
    "            .join(\n",
    "                RECRUITMENT_MODEL.classes.application,\n",
    "                RECRUITMENT_MODEL.classes.candidate.id == RECRUITMENT_MODEL.classes.application.candidate_id,\n",
    "            )\n",
    "            .join(\n",
    "                RECRUITMENT_MODEL.classes.offer,\n",
    "                RECRUITMENT_MODEL.classes.application.job_offer_id == RECRUITMENT_MODEL.classes.offer.id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def applied_for_company(self, company: str) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.offer.company == company\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def has_application_status(self, status: str) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.application.status == status\n",
    "\n",
    "    @decorators.view_filter()\n",
    "    def at_least_experience(self, years: int) -> sqlalchemy.ColumnElement:\n",
    "        return RECRUITMENT_MODEL.classes.candidate.years_of_experience >= years\n",
    "\n",
    "\n",
    "async def ask_dbally(question: str):\n",
    "    llm = LiteLLM(api_key=API_KEY)\n",
    "    recruitment_db = dbally.create_collection(\"recruitment\", llm, event_handlers=[CLIEventHandler()])\n",
    "    recruitment_db.add(RecruitmentView, lambda: RecruitmentView(ENGINE))\n",
    "\n",
    "    await recruitment_db.ask(question, return_natural_response=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFlj5Wm9Rf5u"
   },
   "source": [
    "Now, Let's test it. Start with the example below, and try to ask another questions, see results and analyze the prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8zuVHuBE0gW"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Which candidates with more than 3 years of experience succesfully applied to TestTech Corp?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwrHsQ3jR-vz"
   },
   "source": [
    "Notice, the obtained SQL query\n",
    "\n",
    "```sql\n",
    "SELECT candidate.id, candidate.name, candidate.country, candidate.years_of_experience, candidate.position,         \n",
    "candidate.university, candidate.skills, candidate.tags                                                             \n",
    "FROM candidate JOIN application ON candidate.id = application.candidate_id JOIN offer ON application.job_offer_id =\n",
    "offer.id                                                                                                           \n",
    "WHERE candidate.years_of_experience >= 3 AND offer.company = 'TestTech Corp' AND application.status = 'True'\n",
    "```\n",
    "\n",
    "To wrap things up, we try to ask the very first question once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Somt69CJRssT"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Which candidates have more than 5 years of experience?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpAt9fWrSPJD"
   },
   "source": [
    "Move back to the first response and notice the difference in the returned number of rows.\n",
    "\n",
    "```\n",
    "first response (without joined view):\n",
    "  REQUEST OUTPUT:\n",
    "\n",
    "  Number of rows: 29\n",
    "\n",
    "second response (with joined view):\n",
    "  REQUEST OUTPUT:\n",
    "\n",
    "  Number of rows: 32\n",
    "\n",
    "```\n",
    "\n",
    "this time query returned more rows then previously. This is due to joined view and the fact that same candidate can apply on many offers and it counts too.\n",
    "\n",
    "We can solve this by adding both previously defined views to the Collection [(see more info)](https://db-ally.deepsense.ai/concepts/collections/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIUNgmcFTJ1n"
   },
   "outputs": [],
   "source": [
    "async def ask_dbally(question: str):\n",
    "    llm = LiteLLM(api_key=API_KEY)\n",
    "    recruitment_db = dbally.create_collection(\"recruitment\", llm, event_handlers=[CLIEventHandler()])\n",
    "    recruitment_db.add(CandidateView, lambda: CandidateView(ENGINE))\n",
    "    recruitment_db.add(RecruitmentView, lambda: RecruitmentView(ENGINE))\n",
    "\n",
    "    await recruitment_db.ask(question, return_natural_response=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtcfmJB_UL1v"
   },
   "source": [
    "Shall we test it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbexk0fOU1MZ"
   },
   "outputs": [],
   "source": [
    "await ask_dbally(\"Which candidates have more than 5 years of experience?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ86-4PPU40f"
   },
   "source": [
    "Now pay attention to the additional phase that was run at the very beginning - [View Selection](https://db-ally.deepsense.ai/concepts/views/).\n",
    "\n",
    "```\n",
    "First you need to select a class to query, based on its description and the user question. You have the following  \n",
    "classes to choose from:                                                                                            \n",
    "CandidateView: View meant for answering questions just about the candidates.                                       \n",
    "RecruitmentView: Joined view of the entire database, meant for answering questions mixing candidate, job_offer and\n",
    "application tables.\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "RESPONSE: CandidateView\n",
    "```\n",
    "\n",
    "All defined filters with their description were given to the LLM, and it was asked to select the most appropriate view for the query. The rest is exactly the same.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Congratulations, we did it! We created the dbally agent that can handle the recruitment database very well.\n",
    "\n",
    "Now it's time for you to explore more topics and extend this chatbot with them:\n",
    "* [Similarity Index](https://db-ally.deepsense.ai/how-to/implementing_similarity_index/)\n",
    "* [Integration with Langsmith](https://db-ally.deepsense.ai/how-to/log_runs_to_langsmith/)\n",
    "* ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
