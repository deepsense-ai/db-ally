# How-To: OpenAI Assistants integration

You can expand the toolset of your OpenAI Assistant with dbally by utilizing `OpenAIAdapter`.

To achieve it, you need to perform 4 steps:

1. Initialize `OpenAIAdapter` with pass previously created [`Collection`](../concepts/collections.md)
2. Include JSON definition generated by db-ally's `OpenAIAdapter.generate_function_json` with your request to OpenAI
3. Pass Assistant answer through `OpenAIAdapter.process_response` to obtain dbally response
4. Parse dbally response with `OpenAIAdapter.process_functions_executions` to get format compliant with OpenAI API and ready to be submitted back to Assistants API.

```py hl_lines="6 11 19 23"
from openai import OpenAI
from dbally.adapters.openai_adapter import OpenAIAdapter

client = OpenAI()

adapter = OpenAIAdapter(collection=YOUR_COLLECTION)

assistant = client.beta.assistants.create(
    name="Assistant",
    instructions="You are a helpful assistant",
    tools=[adapter.generate_function_json()],
    model="gpt-4-turbo-preview",
)

# Create your assistants thread, messages and run

if run.status == "requires_action":
    tool_calls = run.required_action.submit_tool_outputs.tool_calls
    response = await adapter.process_response(tool_calls)

    # Implement your custom logic operating on the response: List[OpenAIDballyResponse]

    response_parsed_for_gpt = adapter.process_functions_execution(response)
    run = client.beta.threads.runs.submit_tool_outputs(
                thread_id=thread.id,
                run_id=run.id,
                tool_outputs=response_parsed_for_gpt
            )
```

!!! info
    `process_response` function returns `List[OpenAIDballyResponse]`, which contains `tool_call_id`, `status` and `output` fields. In case of an exception occurring during a dbally call, by default no exception will be raised and status will be set accordingly (you can change it by setting `raise_exception=True`).